{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7aba49f9",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This notebook builds on the cleaned dataset from the preprocessing stage and\n",
    "implements the feature engineering steps needed to prepare the data for model\n",
    "training. The goal here is to enrich the dataset with leakage-safe encodings,\n",
    "interaction terms, and final feature selection before training a baseline model.\n",
    "\n",
    "We load the processed data, apply out-of-fold target encoding to key categorical\n",
    "fields, construct interaction features that capture cross-effects between\n",
    "important signals, and prepare the final training, validation, and test\n",
    "matrices used for modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203c2b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "project_root = next(\n",
    "    (p for p in [Path.cwd()] + list(Path.cwd().parents) if (p / \"src\").exists()),\n",
    "    Path.cwd()\n",
    ")\n",
    "\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b10a9330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module imports \n",
    "from src.preprocessing_imputation import preprocess_impute\n",
    "from src.feature_engineering import (\n",
    "    TargetEncoderOOF,\n",
    "    FeatureInteractionBuilder,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bde40bd",
   "metadata": {},
   "source": [
    "## 1. Load Model-Ready Preprocessed Data\n",
    "\n",
    "We begin by loading the preprocessed dataset produced in the previous notebook.\n",
    "Some columns are downcast from 64-bit to 32-bit where safe, reducing memory\n",
    "usage without affecting model performance.\n",
    "\n",
    "At this stage, the data is free of missing values and already enriched with\n",
    "temporal, order-level, store-level, and market load features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48aa9948",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(project_root / \"data\" / \"processed\" / \"preprocessed_data.parquet\",\n",
    "                     engine=\"pyarrow\")\n",
    "\n",
    "# Columns to convert to int32\n",
    "int64_to_int32 = [\n",
    "    \"order_subtotal_bucket\",\n",
    "    \"order_total_items_bucket\",\n",
    "    \"order_distinct_items_bucket\",\n",
    "    \"store_order_volume\"\n",
    "]\n",
    "\n",
    "df[int64_to_int32] = df[int64_to_int32].astype(\"int32\")\n",
    "\n",
    "# Columns to convert to float32 (exclude target!)\n",
    "float64_to_float32 = [\n",
    "    \"time_hour_sin\", \"time_hour_cos\",\n",
    "    \"time_dow_sin\", \"time_dow_cos\",\n",
    "    \"order_avg_item_price\",\n",
    "    \"order_percent_distinct_items\",\n",
    "    \"load_roll_outstanding_mean\",\n",
    "    \"load_roll_onshift_mean\",\n",
    "    \"load_roll_busy_mean\",\n",
    "    \"load_roll_busy_ratio_mean\",\n",
    "    \"load_roll_demand_supply_mean\",\n",
    "    \"load_roll_outstanding_std\",\n",
    "    \"load_roll_busy_std\",\n",
    "    \"load_recent_order_count\",\n",
    "    \"load_demand_momentum\",\n",
    "    \"load_supply_momentum\",\n",
    "    \"load_busy_momentum\",\n",
    "    \"load_utilization_volatility\",\n",
    "    \"load_pressure_index\",\n",
    "    \"total_onshift_dashers_lag_5min\",\n",
    "    \"total_onshift_dashers_lag_15min\",\n",
    "    \"total_onshift_dashers_lag_30min\",\n",
    "    \"total_busy_dashers_lag_5min\",\n",
    "    \"total_busy_dashers_lag_15min\",\n",
    "    \"total_busy_dashers_lag_30min\",\n",
    "    \"total_outstanding_orders_lag_5min\",\n",
    "    \"total_outstanding_orders_lag_15min\",\n",
    "    \"total_outstanding_orders_lag_30min\",\n",
    "    \"load_busy_ratio_lag_5min\",\n",
    "    \"load_busy_ratio_lag_15min\",\n",
    "    \"load_busy_ratio_lag_30min\",\n",
    "    \"load_demand_supply_ratio_lag_5min\",\n",
    "    \"load_demand_supply_ratio_lag_15min\",\n",
    "    \"load_demand_supply_ratio_lag_30min\",\n",
    "    \"total_onshift_dashers_roll10_std\",\n",
    "    \"total_busy_dashers_roll10_std\",\n",
    "    \"total_outstanding_orders_roll10_std\",\n",
    "    \"load_busy_ratio_roll10_std\",\n",
    "    \"load_demand_supply_ratio_roll10_std\",\n",
    "    \"demand_spike_15m\",\n",
    "    \"supply_drop_15m\",\n",
    "    \"busy_growth_15m\",\n",
    "    \"burst_index\",\n",
    "]\n",
    "\n",
    "df[float64_to_float32] = df[float64_to_float32].astype(\"float32\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545e3da2",
   "metadata": {},
   "source": [
    "## 2. Time-Based Train/Validation/Test Split\n",
    "\n",
    "To mimic real-world forecasting conditions, the dataset is split\n",
    "chronologically:\n",
    "\n",
    "- **Train:** earliest 70%  \n",
    "- **Validation:** next 15%  \n",
    "- **Test:** most recent 15%\n",
    "\n",
    "This ensures the model never learns from future data and reflects realistic\n",
    "production behavior.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ebdbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Split Data \n",
    "cutoff_1 = df.created_at.quantile(0.70)\n",
    "cutoff_2 = df.created_at.quantile(0.85)\n",
    "\n",
    "train_df = df[df.created_at < cutoff_1].copy()\n",
    "valid_df = df[(df.created_at >= cutoff_1) & (df.created_at < cutoff_2)].copy()\n",
    "test_df  = df[df.created_at >= cutoff_2].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96c8011",
   "metadata": {},
   "source": [
    "## 3. Leakage-Safe Target Encoding\n",
    "\n",
    "Several categorical fields, such as store_id, market_id, category, and\n",
    "order_protocol, contain thousands of levels or highly uneven distributions.\n",
    "\n",
    "We apply a leakage-safe K-Fold target encoder that replaces each category with\n",
    "the average delivery time observed *in the other folds* of the training set.\n",
    "This technique captures category-specific behavior without letting the model\n",
    "see its own target.\n",
    "\n",
    "- The **training set** receives out-of-fold (OOF) encoded features.\n",
    "- The **validation and test sets** receive the final encoding trained on the\n",
    "  entire training split.\n",
    "\n",
    "This produces stable, leakage-free numerical representations of the major\n",
    "categorical features across all splits.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd874161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize target encoders\n",
    "cat_encoder = TargetEncoderOOF(\n",
    "    col=\"store_primary_category\",\n",
    "    target_col=\"target_delivery_seconds\",\n",
    "    n_folds=5,\n",
    "    smoothing=10\n",
    ")\n",
    "\n",
    "store_embedder = TargetEncoderOOF(\n",
    "    col=\"store_id\",\n",
    "    target_col=\"target_delivery_seconds\",\n",
    "    n_folds=5,\n",
    "    smoothing=10\n",
    ")\n",
    "\n",
    "market_encoder = TargetEncoderOOF(\n",
    "    col=\"market_id\",\n",
    "    target_col=\"target_delivery_seconds\",\n",
    "    n_folds=5,\n",
    "    smoothing=10\n",
    ")\n",
    "\n",
    "protocol_encoder = TargetEncoderOOF(\n",
    "    col=\"order_protocol\",\n",
    "    target_col=\"target_delivery_seconds\",\n",
    "    n_folds=5,\n",
    "    smoothing=10\n",
    ")\n",
    "\n",
    "# Fit encoders on training data\n",
    "cat_encoder.fit(train_df)\n",
    "store_embedder.fit(train_df)\n",
    "market_encoder.fit(train_df)\n",
    "protocol_encoder.fit(train_df)\n",
    "\n",
    "# Use K-fold out-of-fold encoding for training set\n",
    "train_df = cat_encoder.transform(train_df, is_training=True)\n",
    "train_df = store_embedder.transform(train_df, is_training=True)\n",
    "train_df = market_encoder.transform(train_df, is_training=True)\n",
    "train_df = protocol_encoder.transform(train_df, is_training=True)\n",
    "# Use regular encoding for validation and test sets\n",
    "valid_df = cat_encoder.transform(valid_df, is_training=False)\n",
    "valid_df = store_embedder.transform(valid_df, is_training=False)\n",
    "valid_df = market_encoder.transform(valid_df, is_training=False)\n",
    "valid_df = protocol_encoder.transform(valid_df, is_training=False)\n",
    "\n",
    "test_df = cat_encoder.transform(test_df, is_training=False)\n",
    "test_df = store_embedder.transform(test_df, is_training=False)\n",
    "test_df = market_encoder.transform(test_df, is_training=False)\n",
    "test_df = protocol_encoder.transform(test_df, is_training=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e20480",
   "metadata": {},
   "source": [
    "## 4. Interaction Features\n",
    "\n",
    "Certain operational phenomena involve relationships between multiple features:\n",
    "for example, whether high order volume matters more at busy markets, or whether\n",
    "a costly order interacts with store performance.\n",
    "\n",
    "We construct a small set of targeted interaction terms, including:\n",
    "\n",
    "- subtotal × store encoding  \n",
    "- item count × busy ratio  \n",
    "- time-of-day × demand/supply ratio  \n",
    "- store encoding × average item price  \n",
    "\n",
    "These interactions help the model learn joint effects that may not be captured\n",
    "by individual features alone.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2da17deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interaction features created successfully.\n",
      "['interaction__order_subtotal__x__store_id_encoded', 'interaction__order_total_items__x__load_busy_ratio', 'interaction__time_hour_sin__x__load_demand_supply_ratio', 'interaction__store_id_encoded__x__order_avg_item_price']\n"
     ]
    }
   ],
   "source": [
    "interaction_pairs = [\n",
    "    # Interaction 1: Does a big order matter more at a slow store?\n",
    "    (\"order_subtotal\", \"store_id_encoded\"), \n",
    "    \n",
    "    # Interaction 2: Does volume matter more when the fleet is busy?\n",
    "    (\"order_total_items\", \"load_busy_ratio\"),\n",
    "    \n",
    "    # Interaction 3: Does time of day amplifiy supply/demand mismatches?\n",
    "    (\"time_hour_sin\", \"load_demand_supply_ratio\"),\n",
    "    \n",
    "    # Interaction 4: Do expensive items take longer at slow stores?\n",
    "    (\"store_id_encoded\", \"order_avg_item_price\"),\n",
    "]\n",
    "\n",
    "interactions = FeatureInteractionBuilder(interactions=interaction_pairs)\n",
    "\n",
    "train_df = interactions.transform(train_df)\n",
    "valid_df = interactions.transform(valid_df)\n",
    "test_df  = interactions.transform(test_df)\n",
    "\n",
    "print(\"Interaction features created successfully.\")\n",
    "print([c for c in train_df.columns if \"interaction\" in c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "168fcfe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (137399, 92) Valid: (29443, 92) Test: (29443, 92)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train:\", train_df.shape, \"Valid:\", valid_df.shape, \"Test:\", test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe61e992",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_parquet(project_root / \"data\" / \"processed\" / \"train_features.parquet\")\n",
    "valid_df.to_parquet(project_root / \"data\" / \"processed\" / \"valid_features.parquet\")\n",
    "test_df.to_parquet(project_root / \"data\" / \"processed\" / \"test_features.parquet\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985dc54a",
   "metadata": {},
   "source": [
    "## 5. Baseline LightGBM Model\n",
    "\n",
    "To evaluate the quality of the engineered features, we train a baseline\n",
    "LightGBM regression model using:\n",
    "\n",
    "- all engineered features,\n",
    "- early stopping on the validation set,\n",
    "- MAE and RMSE as evaluation metrics.\n",
    "\n",
    "This baseline helps verify that our encodings, splits, and interaction terms\n",
    "lead to stable, predictive signals before experimenting with more advanced\n",
    "methods.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "497e1087",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_COLS = [\n",
    "    col for col in train_df.columns\n",
    "    if col not in [\n",
    "        # 1. Target & Timestamps (Standard Exclusions)\n",
    "        \"created_at\",\n",
    "        \"actual_delivery_time\",\n",
    "        \"target_delivery_seconds\",\n",
    "        \"market_id\", \n",
    "        \"store_id\", \n",
    "        \"store_primary_category\", \n",
    "        \"order_protocol\"\n",
    "    ]\n",
    "]\n",
    "\n",
    "X_train = train_df[FEATURE_COLS]\n",
    "y_train = train_df[\"target_delivery_seconds\"]\n",
    "\n",
    "X_valid = valid_df[FEATURE_COLS]\n",
    "y_valid = valid_df[\"target_delivery_seconds\"]\n",
    "\n",
    "X_test  = test_df[FEATURE_COLS]\n",
    "y_test  = test_df[\"target_delivery_seconds\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e2633fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017957 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 14414\n",
      "[LightGBM] [Info] Number of data points in the train set: 137399, number of used features: 85\n",
      "[LightGBM] [Info] Start training from score 2812.942736\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[78]\ttraining's l1: 577.033\ttraining's rmse: 764.58\tvalid_1's l1: 583.254\tvalid_1's rmse: 778.346\n",
      "\n",
      "------------- Validation Results -------------\n",
      "MAE  (valid): 583.25 seconds\n",
      "RMSE (valid): 778.35 seconds\n",
      "\n",
      "------------- Test Results -------------\n",
      "MAE  (test): 617.05 seconds\n",
      "RMSE (test): 828.51 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>interaction__time_hour_sin__x__load_demand_sup...</td>\n",
       "      <td>1.491512e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>store_id_encoded</td>\n",
       "      <td>1.111429e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>time_estimated_store_to_consumer_driving_duration</td>\n",
       "      <td>6.097951e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>load_roll_demand_supply_mean</td>\n",
       "      <td>4.568404e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>interaction__order_subtotal__x__store_id_encoded</td>\n",
       "      <td>3.153286e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>load_demand_supply_ratio</td>\n",
       "      <td>1.891919e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>time_minute_of_day</td>\n",
       "      <td>1.739533e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>load_demand_supply_ratio_lag_5min</td>\n",
       "      <td>1.437883e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>bucket_distance</td>\n",
       "      <td>1.340611e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>time_hour_sin</td>\n",
       "      <td>1.150508e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>time_day_of_week</td>\n",
       "      <td>1.028587e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>total_onshift_dashers</td>\n",
       "      <td>1.009372e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>store_order_volume</td>\n",
       "      <td>8.404596e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>time_month</td>\n",
       "      <td>5.625676e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>market_id_encoded</td>\n",
       "      <td>5.571388e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>load_orders_per_busy_dasher</td>\n",
       "      <td>5.298778e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>time_dow_sin</td>\n",
       "      <td>5.142369e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>total_busy_dashers</td>\n",
       "      <td>4.828207e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>order_protocol_encoded</td>\n",
       "      <td>4.815053e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>order_high_value</td>\n",
       "      <td>3.946796e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              feature    importance\n",
       "83  interaction__time_hour_sin__x__load_demand_sup...  1.491512e+11\n",
       "78                                   store_id_encoded  1.111429e+11\n",
       "9   time_estimated_store_to_consumer_driving_duration  6.097951e+10\n",
       "39                       load_roll_demand_supply_mean  4.568404e+10\n",
       "81   interaction__order_subtotal__x__store_id_encoded  3.153286e+10\n",
       "33                           load_demand_supply_ratio  1.891919e+10\n",
       "15                                 time_minute_of_day  1.739533e+10\n",
       "61                  load_demand_supply_ratio_lag_5min  1.437883e+10\n",
       "75                                    bucket_distance  1.340611e+10\n",
       "17                                      time_hour_sin  1.150508e+10\n",
       "11                                   time_day_of_week  1.028587e+10\n",
       "5                               total_onshift_dashers  1.009372e+10\n",
       "31                                 store_order_volume  8.404596e+09\n",
       "12                                         time_month  5.625676e+09\n",
       "79                                  market_id_encoded  5.571388e+09\n",
       "34                        load_orders_per_busy_dasher  5.298778e+09\n",
       "19                                       time_dow_sin  5.142369e+09\n",
       "6                                  total_busy_dashers  4.828207e+09\n",
       "80                             order_protocol_encoded  4.815053e+09\n",
       "25                                   order_high_value  3.946796e+09"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline LightGBM Model\n",
    "params = {\n",
    "    \"objective\": \"regression\",\n",
    "    \"metric\": [\"mae\", \"rmse\"],\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"num_leaves\": 64,\n",
    "    \"feature_fraction\": 0.9,\n",
    "    \"bagging_fraction\": 0.9,\n",
    "    \"bagging_freq\": 5,\n",
    "    \"seed\": 42,\n",
    "    \"early_stopping_rounds\": 100,\n",
    "}\n",
    "\n",
    "train_set = lgb.Dataset(X_train, y_train)\n",
    "valid_set = lgb.Dataset(X_valid, y_valid)\n",
    "\n",
    "params = dict(params)\n",
    "params[\"early_stopping_round\"] = 100\n",
    "params.setdefault(\"verbosity\", 1)\n",
    "\n",
    "model = lgb.train(\n",
    "    params,\n",
    "    train_set,\n",
    "    valid_sets=[train_set, valid_set],\n",
    "    num_boost_round=2000\n",
    ")\n",
    "\n",
    "# ensure predictions are numpy arrays (avoid sparse / list types for sklearn metrics)\n",
    "pred_valid = np.asarray(model.predict(X_valid)).ravel()\n",
    "pred_test = np.asarray(model.predict(X_test)).ravel()\n",
    "\n",
    "mae_valid = mean_absolute_error(y_valid, pred_valid)\n",
    "rmse_valid = np.sqrt(mean_squared_error(y_valid, pred_valid))\n",
    "\n",
    "mae_test = mean_absolute_error(y_test, pred_test)\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, pred_test))\n",
    "\n",
    "print(\"\\n------------- Validation Results -------------\")\n",
    "print(f\"MAE  (valid): {mae_valid:,.2f} seconds\")\n",
    "print(f\"RMSE (valid): {rmse_valid:,.2f} seconds\")\n",
    "\n",
    "print(\"\\n------------- Test Results -------------\")\n",
    "print(f\"MAE  (test): {mae_test:,.2f} seconds\")\n",
    "print(f\"RMSE (test): {rmse_test:,.2f} seconds\")\n",
    "\n",
    "importances = model.feature_importance(importance_type=\"gain\")\n",
    "feat_imp = (\n",
    "    pd.DataFrame({\n",
    "        \"feature\": model.feature_name(), \n",
    "        \"importance\": importances\n",
    "    })\n",
    "    .sort_values(\"importance\", ascending=False)\n",
    ")\n",
    "\n",
    "feat_imp.head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2287809",
   "metadata": {},
   "source": [
    "## 6. Feature Importance Review\n",
    "\n",
    "LightGBM’s gain-based feature importance highlights the strongest predictors\n",
    "in the engineered dataset. This step provides an early look at:\n",
    "\n",
    "- which encoded categories carry the most signal,\n",
    "- which marketplace load features are most influential,\n",
    "- whether interaction terms meaningfully contribute to model performance.\n",
    "\n",
    "These insights inform further feature refinement and model tuning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0af6319",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook transformed the preprocessed dataset into a fully engineered,\n",
    "model-ready feature matrix by applying leakage-safe target encoding, building\n",
    "select interaction features, and constructing a clean train/valid/test split.\n",
    "\n",
    "With these engineered features showing strong baseline performance, the next\n",
    "steps involve model tuning, evaluation across multiple algorithms, and\n",
    "refinement of the most impactful signals.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
